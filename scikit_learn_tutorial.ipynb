{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "488a9c9a",
   "metadata": {},
   "source": [
    "# Install and Import Libraries\n",
    "Install Scikit-learn if not already installed and import necessary libraries such as pandas, numpy, and sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67088e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Scikit-learn\n",
    "# Uncomment the line below if Scikit-learn is not installed\n",
    "# !pip install scikit-learn\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b14ad0",
   "metadata": {},
   "source": [
    "# Load Dataset\n",
    "Load a sample dataset using Scikit-learn's built-in datasets or an external dataset using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29784a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: [[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n",
      "Labels: [0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Load a sample dataset\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "print(\"Features:\", X[:5])\n",
    "print(\"Labels:\", y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cad69b",
   "metadata": {},
   "source": [
    "# Preprocess Data\n",
    "Handle missing values, encode categorical variables, and scale numerical features using Scikit-learn preprocessing tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "686d0384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled Features: [[-0.90068117  1.01900435 -1.34022653 -1.3154443 ]\n",
      " [-1.14301691 -0.13197948 -1.34022653 -1.3154443 ]\n",
      " [-1.38535265  0.32841405 -1.39706395 -1.3154443 ]\n",
      " [-1.50652052  0.09821729 -1.2833891  -1.3154443 ]\n",
      " [-1.02184904  1.24920112 -1.34022653 -1.3154443 ]]\n"
     ]
    }
   ],
   "source": [
    "# Preprocess data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "print(\"Scaled Features:\", X_scaled[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e298d43",
   "metadata": {},
   "source": [
    "# Split Dataset\n",
    "Split the dataset into training and testing sets using train_test_split from Scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b37f21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (120, 4)\n",
      "Test set size: (30, 4)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "print(\"Training set size:\", X_train.shape)\n",
    "print(\"Test set size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e308c7",
   "metadata": {},
   "source": [
    "# Train a Model\n",
    "Train a machine learning model (e.g., Linear Regression, Decision Tree, or Random Forest) using Scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7864c983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained successfully.\n"
     ]
    }
   ],
   "source": [
    "# Train a model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model trained successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42ec4db",
   "metadata": {},
   "source": [
    "# Evaluate the Model\n",
    "Evaluate the model's performance using metrics such as accuracy, precision, recall, or mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af3ec0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7d31ea",
   "metadata": {},
   "source": [
    "# Make Predictions\n",
    "Use the trained model to make predictions on new or test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "622846fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [1 0 2 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "new_data = X_test[:5]\n",
    "predictions = model.predict(new_data)\n",
    "print(\"Predictions:\", predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
